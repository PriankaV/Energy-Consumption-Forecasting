{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03fe2b8-b627-4a3c-bf32-d0148fbde471",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d8fe3a-c59a-465e-9b84-8fe1c8733d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data for: AEP\n",
      "Preprocessed data for: COMED\n",
      "Preprocessed data for: DAYTON\n",
      "Preprocessed data for: DEOK\n",
      "Preprocessed data for: DOM\n",
      "Preprocessed data for: DUQ\n",
      "Preprocessed data for: EKPC\n",
      "Preprocessed data for: FE\n",
      "Preprocessed data for: NI\n",
      "Preprocessed data for: PJMW\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the base directory\n",
    "notebook_dir = os.getcwd()\n",
    "base_dir = os.path.join(notebook_dir, 'Hourly Energy Consumption')\n",
    "\n",
    "# Define utilities with file names\n",
    "utilities = {\n",
    "    'AEP': 'AEP_hourly.csv',\n",
    "    'COMED': 'COMED_hourly.csv',\n",
    "    'DAYTON': 'DAYTON_hourly.csv',\n",
    "    'DEOK': 'DEOK_hourly.csv',\n",
    "    'DOM': 'DOM_hourly.csv',\n",
    "    'DUQ': 'DUQ_hourly.csv',\n",
    "    'EKPC': 'EKPC_hourly.csv',\n",
    "    'FE': 'FE_hourly.csv',\n",
    "    'NI': 'Ni_hourly.csv',\n",
    "    'PJMW': 'PJMW_hourly.csv'\n",
    "}\n",
    "\n",
    "# Function to remove outliers\n",
    "def remove_outliers(series, threshold=3):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    return series[(series > mean - threshold * std) & (series < mean + threshold * std)]\n",
    "\n",
    "# Function to handle duplicate timestamps\n",
    "def handle_duplicates(df, mw_col):\n",
    "    # Group by index and aggregate using mean\n",
    "    df = df.groupby(df.index).mean()\n",
    "    return df\n",
    "\n",
    "# Preprocess function that loads data, handles outliers, duplicates, and adds time-based features\n",
    "def preprocess_data(file_path, mw_col):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "\n",
    "    # Handle duplicates\n",
    "    df = handle_duplicates(df, mw_col=mw_col)\n",
    "\n",
    "    # Remove outliers\n",
    "    df[mw_col] = remove_outliers(df[mw_col])\n",
    "\n",
    "    # Drop any remaining missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Add time-based features: hour, day_of_week, and month\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    return df\n",
    "\n",
    "# Go over all utilities and preprocess the data\n",
    "processed_data = {}\n",
    "for utility, filename in utilities.items():\n",
    "    file_path = os.path.join(base_dir, filename)\n",
    "    df = preprocess_data(file_path, mw_col=f'{utility}_MW')\n",
    "    if not df.empty:\n",
    "        print(f\"Preprocessed data for: {utility}\")\n",
    "    else:\n",
    "        print(f\"Skipping {utility} due to insufficient data.\")\n",
    "    processed_data[utility] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48575ac8-091f-4691-ae7d-8e0f7ef315cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data for AEP:\n",
      "                      AEP_MW  hour  day_of_week  month\n",
      "Datetime                                              \n",
      "2004-10-01 01:00:00  12379.0     1            4     10\n",
      "2004-10-01 02:00:00  11935.0     2            4     10\n",
      "2004-10-01 03:00:00  11692.0     3            4     10\n",
      "2004-10-01 04:00:00  11597.0     4            4     10\n",
      "2004-10-01 05:00:00  11681.0     5            4     10\n",
      "Preprocessed data for COMED:\n",
      "                     COMED_MW  hour  day_of_week  month\n",
      "Datetime                                               \n",
      "2011-01-01 01:00:00    9631.0     1            5      1\n",
      "2011-01-01 02:00:00    9273.0     2            5      1\n",
      "2011-01-01 03:00:00    9011.0     3            5      1\n",
      "2011-01-01 04:00:00    8741.0     4            5      1\n",
      "2011-01-01 05:00:00    8694.0     5            5      1\n",
      "Preprocessed data for DAYTON:\n",
      "                     DAYTON_MW  hour  day_of_week  month\n",
      "Datetime                                                \n",
      "2004-10-01 01:00:00     1621.0     1            4     10\n",
      "2004-10-01 02:00:00     1536.0     2            4     10\n",
      "2004-10-01 03:00:00     1500.0     3            4     10\n",
      "2004-10-01 04:00:00     1434.0     4            4     10\n",
      "2004-10-01 05:00:00     1489.0     5            4     10\n",
      "Preprocessed data for DEOK:\n",
      "                     DEOK_MW  hour  day_of_week  month\n",
      "Datetime                                              \n",
      "2012-01-01 01:00:00   2533.0     1            6      1\n",
      "2012-01-01 02:00:00   2465.0     2            6      1\n",
      "2012-01-01 03:00:00   2364.0     3            6      1\n",
      "2012-01-01 04:00:00   2313.0     4            6      1\n",
      "2012-01-01 05:00:00   2279.0     5            6      1\n",
      "Preprocessed data for DOM:\n",
      "                     DOM_MW  hour  day_of_week  month\n",
      "Datetime                                             \n",
      "2005-05-01 01:00:00  7190.0     1            6      5\n",
      "2005-05-01 02:00:00  6803.0     2            6      5\n",
      "2005-05-01 03:00:00  6583.0     3            6      5\n",
      "2005-05-01 04:00:00  6452.0     4            6      5\n",
      "2005-05-01 05:00:00  6445.0     5            6      5\n",
      "Preprocessed data for DUQ:\n",
      "                     DUQ_MW  hour  day_of_week  month\n",
      "Datetime                                             \n",
      "2005-01-01 01:00:00  1364.0     1            5      1\n",
      "2005-01-01 02:00:00  1273.0     2            5      1\n",
      "2005-01-01 03:00:00  1218.0     3            5      1\n",
      "2005-01-01 04:00:00  1170.0     4            5      1\n",
      "2005-01-01 05:00:00  1166.0     5            5      1\n",
      "Preprocessed data for EKPC:\n",
      "                     EKPC_MW  hour  day_of_week  month\n",
      "Datetime                                              \n",
      "2013-06-01 01:00:00   1166.0     1            5      6\n",
      "2013-06-01 02:00:00   1098.0     2            5      6\n",
      "2013-06-01 03:00:00   1036.0     3            5      6\n",
      "2013-06-01 04:00:00   1023.0     4            5      6\n",
      "2013-06-01 05:00:00    949.0     5            5      6\n",
      "Preprocessed data for FE:\n",
      "                      FE_MW  hour  day_of_week  month\n",
      "Datetime                                             \n",
      "2011-06-01 02:00:00  8548.0     2            2      6\n",
      "2011-06-01 03:00:00  8121.0     3            2      6\n",
      "2011-06-01 04:00:00  7801.0     4            2      6\n",
      "2011-06-01 05:00:00  7729.0     5            2      6\n",
      "2011-06-01 06:00:00  7968.0     6            2      6\n",
      "Preprocessed data for NI:\n",
      "                      NI_MW  hour  day_of_week  month\n",
      "Datetime                                             \n",
      "2004-05-01 01:00:00  9198.0     1            5      5\n",
      "2004-05-01 02:00:00  8570.0     2            5      5\n",
      "2004-05-01 03:00:00  8183.0     3            5      5\n",
      "2004-05-01 04:00:00  7917.0     4            5      5\n",
      "2004-05-01 05:00:00  7828.0     5            5      5\n",
      "Preprocessed data for PJMW:\n",
      "                     PJMW_MW  hour  day_of_week  month\n",
      "Datetime                                              \n",
      "2002-04-01 01:00:00   4374.0     1            0      4\n",
      "2002-04-01 02:00:00   4306.0     2            0      4\n",
      "2002-04-01 03:00:00   4322.0     3            0      4\n",
      "2002-04-01 04:00:00   4359.0     4            0      4\n",
      "2002-04-01 05:00:00   4436.0     5            0      4\n"
     ]
    }
   ],
   "source": [
    "# Print data preprocessing results to confirm\n",
    "for utility, df in processed_data.items():\n",
    "    print(f\"Preprocessed data for {utility}:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8ba3c-e97e-46ff-9db9-0f9490d85c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
